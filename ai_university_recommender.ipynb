{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt0cO7C71Mk52vv5DkoJni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajShah3006/Saarthi/blob/main/ai_university_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cad82c67"
      },
      "source": [
        "!pip install requests beautifulsoup4 google-generativeai gradio scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "import time\n",
        "import concurrent.futures\n",
        "import json\n",
        "import os\n",
        "import csv\n",
        "import datetime\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "\n",
        "# --- 1. SETUP & DRIVE ---\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è API Key missing. Please check Colab Secrets.\")\n",
        "\n",
        "print(\"üìÇ Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_FOLDER = \"/content/drive/My Drive/Saarthi_Project_Data\"\n",
        "if not os.path.exists(DRIVE_FOLDER):\n",
        "    os.makedirs(DRIVE_FOLDER)\n",
        "\n",
        "CACHE_FILE = f\"{DRIVE_FOLDER}/university_data_cached.json\"\n",
        "LOG_FILE = f\"{DRIVE_FOLDER}/user_traffic_logs.csv\"\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "# --- 2. DATA CONSTANTS ---\n",
        "GRADE_OPTIONS = [\"Grade 11\", \"Grade 12\", \"Gap Year\"]\n",
        "\n",
        "# (Your Full List Goes Here)\n",
        "ALL_COURSES = [\n",
        "    # --- GRADE 12 COURSES (from your file) ---\n",
        "    \"Dramatic Arts (ADA4M1)\", \"Drama Film/Video (ADV4M1)\",\n",
        "    \"Exploring and Creating in the Arts (AEA4O1)\", \"Guitar Music (AMG4M1)\",\n",
        "    \"Music (AMU4M1)\", \"Visual Arts (AVI4M1)\", \"Visual Arts - Info/Consumer (AWE4M1)\",\n",
        "    \"Visual Arts - Fashion (AWI4M1)\", \"Visual Arts - Drawing (AWM4M1)\",\n",
        "    \"Photography (AWQ4M1)\", \"Visual Arts - Film/Video (AWR4M1)\",\n",
        "    \"Visual Arts - Computer (AWS4M1)\", \"Visual Arts - Non-Traditional (AWT4M1)\",\n",
        "    \"Entrepreneurship: Venture Planning (BDV4C1)\",\n",
        "    \"Environment & Resource Mgmt (CGR4M1)\", \"World Issues (CGW4U1)\",\n",
        "    \"Canada: History, Identity, Culture (CHI4U1)\", \"World History (CHY4U1)\",\n",
        "    \"Canadian & International Law (CLN4U1)\", \"Canadian & World Politics (CPW4U1)\",\n",
        "    \"English (ENG4U1)\", \"English (College) (ENG4C1)\", \"Studies in Literature (ETS4U1)\",\n",
        "    \"The Writer's Craft (EWC4U1)\", \"Nutrition and Health (HFA4U1)\",\n",
        "    \"Personal Life Management (HIP4O1)\", \"Challenge and Change in Society (HSB4U1)\",\n",
        "    \"Equity and Social Justice (HSE4M1)\", \"Philosophy (HZT4U1)\",\n",
        "    \"Interdisciplinary Studies (IDC4U1)\", \"Foundations for College Math (MAP4C1)\",\n",
        "    \"Calculus and Vectors (MCV4U1)\", \"Data Management (MDM4U1)\",\n",
        "    \"Advanced Functions (MHF4U1)\", \"Literacy Course (OLC4O1)\",\n",
        "    \"Personal Fitness (PAF4O1)\", \"Recreation Leadership (PLF4M1)\",\n",
        "    \"Healthy Active Living (PPL4O1)\", \"Kinesiology (PSK4U1)\",\n",
        "    \"Biology (SBI4U1)\", \"Chemistry (SCH4U1)\", \"Physics (SPH4U1)\",\n",
        "\n",
        "    # --- GRADE 11 COURSES (from your file) ---\n",
        "    \"Dramatic Arts (ADA3M1)\", \"Drama Film/Video (ADV3M1)\", \"Guitar Music (AMG3M1)\",\n",
        "    \"Media Arts (ASM3M1)\", \"Visual Arts (AVI3M1)\", \"Visual Arts - Crafts (AWA3M1)\",\n",
        "    \"Visual Arts - Fashion (AWI3M1)\", \"Photography (AWQ3M1)\",\n",
        "    \"Financial Accounting (BAF3M1)\", \"Entrepreneurship (BDI3C1)\",\n",
        "    \"Marketing (BMI3C1)\", \"Forces of Nature (CGF3M1)\", \"Travel and Tourism (CGG3O1)\",\n",
        "    \"Genocide and Crimes Against Humanity (CHG381)\", \"World History to 16th Century (CHW3M1)\",\n",
        "    \"Understanding Canadian Law (CLU3M1)\", \"Media Studies (EMS3O1)\",\n",
        "    \"Food and Culture (HFC3M1)\", \"World Religions (HRT3M1)\",\n",
        "    \"Intro to Anthropology/Psych/Soc (HSP3U1)\", \"Philosophy: Big Questions (HZB3M1)\",\n",
        "    \"Functions (MCR3U1)\", \"Functions & Applications (MCF3M1)\",\n",
        "    \"First Nations, M√©tis, Inuit Voices (NBE3U1)\", \"Biology (SBI3U1)\",\n",
        "    \"Chemistry (SCH3U1)\", \"Physics (SPH3U1)\", \"Environmental Science (SVN3M1)\",\n",
        "    \"Technological Design (TDJ3M1)\", \"Hairstyling and Aesthetics (TXJ3E1)\"\n",
        "]\n",
        "\n",
        "# --- 3. UTILS (FIXED) ---\n",
        "\n",
        "# FIX #1: Added the missing HEADERS variable\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def log_interaction(grade, location, interests, subjects):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    # Only create header if file doesn't exist\n",
        "    if not os.path.exists(LOG_FILE):\n",
        "        with open(LOG_FILE, mode='w', newline='') as f:\n",
        "            csv.writer(f).writerow([\"Timestamp\", \"Grade\", \"Location\", \"Interests\", \"Subjects\"])\n",
        "\n",
        "    with open(LOG_FILE, mode='a', newline='') as f:\n",
        "        csv.writer(f).writerow([timestamp, grade, location, interests, subjects])\n",
        "\n",
        "def save_data(data):\n",
        "    with open(CACHE_FILE, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "def load_data():\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        with open(CACHE_FILE, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            if data and 'program_name' in data[0]:\n",
        "                print(f\"‚ö° Loaded {len(data)} programs from Drive.\")\n",
        "                return data\n",
        "    return None\n",
        "\n",
        "# FIX #2: Added the Batch Embedding function\n",
        "def get_batch_embeddings(text_list):\n",
        "    try:\n",
        "        result = genai.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            content=text_list,\n",
        "            task_type=\"retrieval_document\"\n",
        "        )\n",
        "        return result['embedding']\n",
        "    except Exception as e:\n",
        "        print(f\"Batch Error: {e}\")\n",
        "        return [[0]*768 for _ in range(len(text_list))]\n",
        "\n",
        "def get_single_embedding(text):\n",
        "    try:\n",
        "        result = genai.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            content=str(text)[:2000],\n",
        "            task_type=\"retrieval_query\"\n",
        "        )\n",
        "        return result['embedding']\n",
        "    except: return [0] * 768\n",
        "\n",
        "# --- 4. SCRAPING ---\n",
        "def list_all_programs(url):\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        programs_list = []\n",
        "        for el in soup.select('h2.result-heading'):\n",
        "            programs_list.append({'name': el.get_text(strip=True), 'url': el.find('a', href=True)['href']})\n",
        "        return programs_list\n",
        "    except: return None\n",
        "\n",
        "def scrape_university_info(url):\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        data = {}\n",
        "        prereqs = []\n",
        "        for h in soup.find_all(string=re.compile(r'Prerequisites|Admission Requirements', re.IGNORECASE)):\n",
        "            lst = h.find_next(['ul', 'ol'])\n",
        "            if lst: prereqs.extend([li.get_text(strip=True) for li in lst.select('li')])\n",
        "        data['prerequisites'] = \", \".join(list(set(prereqs))) if prereqs else \"Not listed\"\n",
        "        avg = soup.find(string=re.compile(r'\\d+%', re.IGNORECASE))\n",
        "        data['admission_average'] = avg.strip() if avg else \"Not listed\"\n",
        "        return data\n",
        "    except: return {}\n",
        "\n",
        "# --- 5. MAIN EXECUTION ---\n",
        "all_programs_detailed_data = load_data()\n",
        "\n",
        "if not all_programs_detailed_data:\n",
        "    print(\"üöÄ Starting Scrape...\")\n",
        "    programs_with_urls = []\n",
        "    # Full alphabet required for real scrape\n",
        "    alphabet = ['a', 'b', 'c', 'd-e', 'f-g', 'h', 'i', 'j-l', 'm', 'n-p', 'q-s', 't-z']\n",
        "\n",
        "    for group in alphabet:\n",
        "        res = list_all_programs(f\"https://www.ouinfo.ca/programs/search/?search=&group={group}\")\n",
        "        if res: programs_with_urls.extend(res)\n",
        "\n",
        "    print(f\"‚úÖ Found {len(programs_with_urls)} programs. Deep scraping...\")\n",
        "    scraped_results = []\n",
        "\n",
        "    def process_program(entry):\n",
        "        url = f\"https://www.ouinfo.ca{entry['url']}\"\n",
        "        data = scrape_university_info(url)\n",
        "        return {'program_name': entry['name'], 'program_url': url, **data}\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = {executor.submit(process_program, p): p for p in programs_with_urls}\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            if future.result(): scraped_results.append(future.result())\n",
        "\n",
        "    print(\"üß† Generating Embeddings (Batch Mode)...\")\n",
        "    texts = [f\"{item['program_name']} {item.get('prerequisites','')}\"[:2000] for item in scraped_results]\n",
        "    all_vectors = []\n",
        "\n",
        "    # Process 50 at a time\n",
        "    for i in range(0, len(texts), 50):\n",
        "        print(f\"Embedding batch {i}...\", end=\"\\r\")\n",
        "        all_vectors.extend(get_batch_embeddings(texts[i : i + 50]))\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    all_programs_detailed_data = []\n",
        "    for i, item in enumerate(scraped_results):\n",
        "        if i < len(all_vectors):\n",
        "            item['embedding'] = all_vectors[i]\n",
        "            all_programs_detailed_data.append(item)\n",
        "\n",
        "    save_data(all_programs_detailed_data)\n",
        "\n",
        "# --- 6. LOGIC ---\n",
        "\n",
        "def find_best_matches(query, data, top_k=5):\n",
        "    q_vec = get_single_embedding(query)\n",
        "    valid_data = [x for x in data if 'embedding' in x]\n",
        "    if not valid_data: return data[:5]\n",
        "\n",
        "    db_vecs = [x['embedding'] for x in valid_data]\n",
        "    scores = cosine_similarity([q_vec], db_vecs)[0]\n",
        "    top_indices = scores.argsort()[-top_k:][::-1]\n",
        "    return [valid_data[i] for i in top_indices]\n",
        "\n",
        "def generate_chatbot_response(user_data, relevant_programs):\n",
        "    context = \"\"\n",
        "    for p in relevant_programs:\n",
        "        context += f\"- {p['program_name']} (Avg: {p['admission_average']})\\n\"\n",
        "        context += f\"  Prereqs: {p['prerequisites']}\\n\"\n",
        "        context += f\"  Link: {p['program_url']}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Act as 'Saarthi', a wise university guidance counselor.\n",
        "\n",
        "    STUDENT:\n",
        "    - Interests: {user_data['intrests']}\n",
        "    - Grade: {user_data['grade']}\n",
        "    - Avg: {user_data['overall_average']}\n",
        "    - Courses: {user_data['subjects']}\n",
        "    - Location: {user_data['location']}\n",
        "\n",
        "    OPTIONS:\n",
        "    {context}\n",
        "\n",
        "    TASK:\n",
        "    1. **Rank & Recommend:** Recommend the top 10 programs.\n",
        "    2. **Prerequsite Check:** Compare \"Subjects\" vs \"Prereqs\". Warn if missing.\n",
        "    3. **Fit Analysis:** Explain fit.\n",
        "    4. **Extracurriculars:** Suggest side projects.\n",
        "    5. **COMMUTE ANALYSIS:** - Calculate estimated travel time from '{user_data['location']}' to the university.\n",
        "       - If > 1 hour, recommend RESIDENCE.\n",
        "       - Estimate Cost (GO Train/Gas).\n",
        "    6. **Tone:** Warm and supportive. Use emojis.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return chat.send_message(prompt).text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def web_wrapper(subjects_list, interests, average, grade, location):\n",
        "    # Convert list to string for AI\n",
        "    subjects_str = \", \".join(subjects_list) if subjects_list else \"None\"\n",
        "\n",
        "    log_interaction(grade, location, interests, subjects_str)\n",
        "\n",
        "    user_data = {\n",
        "        'subjects': subjects_str, 'intrests': interests,\n",
        "        'overall_average': average, 'grade': grade, 'location': location\n",
        "    }\n",
        "    matches = find_best_matches(interests, all_programs_detailed_data)\n",
        "    return generate_chatbot_response(user_data, matches)\n",
        "\n",
        "# --- 7. UI ---\n",
        "interface = gr.Interface(\n",
        "    fn=web_wrapper,\n",
        "    inputs=[\n",
        "        # FIX #3: Added allow_custom_value=True so they can type new subjects\n",
        "        gr.Dropdown(\n",
        "            ALL_COURSES,\n",
        "            multiselect=True,\n",
        "            label=\"Subjects\",\n",
        "            info=\"Type to search (e.g. 'Math'). You can also type custom courses.\",\n",
        "            allow_custom_value=True\n",
        "        ),\n",
        "        gr.Textbox(label=\"Interests\"),\n",
        "        gr.Textbox(label=\"Average %\"),\n",
        "        gr.Dropdown(GRADE_OPTIONS, label=\"Grade\"),\n",
        "        gr.Textbox(label=\"Location (City)\"),\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Saarthi Advice\"),\n",
        "    title=\"Saarthi AI\",\n",
        "    description=\"Your Personal University Guide\"\n",
        ")\n",
        "\n",
        "interface.launch(inline=True, share=True, debug=True)"
      ],
      "metadata": {
        "id": "Xy_kErvrEIbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}