{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkpfEQG8QloJn1zp6YnzM2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajShah3006/Saarthi/blob/main/ai_university_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cad82c67"
      },
      "source": [
        "!pip install requests beautifulsoup4 google-generativeai gradio scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "import time\n",
        "import concurrent.futures\n",
        "import json\n",
        "import os\n",
        "import csv\n",
        "import datetime\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "\n",
        "# --- 1. SETUP & DRIVE ---\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è API Key missing.\")\n",
        "\n",
        "print(\"üìÇ Connecting to Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_FOLDER = \"/content/drive/My Drive/Saarthi_Project_Data\"\n",
        "if not os.path.exists(DRIVE_FOLDER):\n",
        "    os.makedirs(DRIVE_FOLDER)\n",
        "\n",
        "CACHE_FILE = f\"{DRIVE_FOLDER}/university_data_cached.json\"\n",
        "LOG_FILE = f\"{DRIVE_FOLDER}/user_traffic_logs.csv\"\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "# --- 2. DATA CONSTANTS ---\n",
        "GRADE_OPTIONS = [\"Grade 11\", \"Grade 12\", \"Gap Year\"]\n",
        "\n",
        "ALL_COURSES = [\n",
        "    \"Dramatic Arts (ADA3M1)\", \"Music (AMU3M1)\", \"Visual Arts (AVI3M1)\",\n",
        "    \"Financial Accounting (BAF3M1)\", \"Entrepreneurship (BDI3C1)\",\n",
        "    \"Physics (SPH3U1)\", \"Biology (SBI3U1)\", \"Chemistry (SCH3U1)\",\n",
        "    \"Functions (MCR3U1)\", \"English (ENG3U1)\", \"Computer Science (ICS3U1)\",\n",
        "    \"Calculus and Vectors (MCV4U1)\", \"Advanced Functions (MHF4U1)\",\n",
        "    \"English (ENG4U1)\", \"Physics (SPH4U1)\", \"Chemistry (SCH4U1)\",\n",
        "    \"Biology (SBI4U1)\", \"Data Management (MDM4U1)\", \"Kinesiology (PSK4U1)\"\n",
        "]\n",
        "\n",
        "# --- 3. UTILS ---\n",
        "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "\n",
        "def log_interaction(grade, location, interests, subjects):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    if not os.path.exists(LOG_FILE):\n",
        "        with open(LOG_FILE, mode='w', newline='') as f:\n",
        "            csv.writer(f).writerow([\"Timestamp\", \"Grade\", \"Location\", \"Interests\", \"Subjects\"])\n",
        "    with open(LOG_FILE, mode='a', newline='') as f:\n",
        "        csv.writer(f).writerow([timestamp, grade, location, interests, subjects])\n",
        "\n",
        "def save_data(data):\n",
        "    with open(CACHE_FILE, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "def load_data():\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        with open(CACHE_FILE, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            if data and 'program_name' in data[0]:\n",
        "                print(f\"‚ö° Loaded {len(data)} programs from Drive.\")\n",
        "                return data\n",
        "    return None\n",
        "\n",
        "def get_batch_embeddings(text_list):\n",
        "    try:\n",
        "        result = genai.embed_content(model=\"models/text-embedding-004\", content=text_list, task_type=\"retrieval_document\")\n",
        "        return result['embedding']\n",
        "    except: return [[0]*768 for _ in range(len(text_list))]\n",
        "\n",
        "def get_single_embedding(text):\n",
        "    try:\n",
        "        result = genai.embed_content(model=\"models/text-embedding-004\", content=str(text)[:2000], task_type=\"retrieval_query\")\n",
        "        return result['embedding']\n",
        "    except: return [0] * 768\n",
        "\n",
        "# --- 4. SCRAPING ---\n",
        "def list_all_programs(url):\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        programs_list = []\n",
        "        for el in soup.select('h2.result-heading'):\n",
        "            programs_list.append({'name': el.get_text(strip=True), 'url': el.find('a', href=True)['href']})\n",
        "        return programs_list\n",
        "    except: return None\n",
        "\n",
        "def scrape_university_info(url):\n",
        "    try:\n",
        "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        data = {}\n",
        "        prereqs = []\n",
        "        for h in soup.find_all(string=re.compile(r'Prerequisites|Admission Requirements', re.IGNORECASE)):\n",
        "            lst = h.find_next(['ul', 'ol'])\n",
        "            if lst: prereqs.extend([li.get_text(strip=True) for li in lst.select('li')])\n",
        "        data['prerequisites'] = \", \".join(list(set(prereqs))) if prereqs else \"Not listed\"\n",
        "        avg = soup.find(string=re.compile(r'\\d+%', re.IGNORECASE))\n",
        "        data['admission_average'] = avg.strip() if avg else \"Not listed\"\n",
        "        return data\n",
        "    except: return {}\n",
        "\n",
        "# --- 5. MAIN EXECUTION ---\n",
        "all_programs_detailed_data = load_data()\n",
        "\n",
        "if not all_programs_detailed_data:\n",
        "    print(\"üöÄ Starting Scrape...\")\n",
        "    programs_with_urls = []\n",
        "    for group in ['a', 'b', 'c', 'd-e', 'f-g', 'h', 'i', 'j-l', 'm', 'n-p', 'q-s', 't-z']:\n",
        "        res = list_all_programs(f\"https://www.ouinfo.ca/programs/search/?search=&group={group}\")\n",
        "        if res: programs_with_urls.extend(res)\n",
        "\n",
        "    print(\"‚è≥ Scraping Details...\")\n",
        "    scraped_results = []\n",
        "    def process_program(entry):\n",
        "        url = f\"https://www.ouinfo.ca{entry['url']}\"\n",
        "        data = scrape_university_info(url)\n",
        "        return {'program_name': entry['name'], 'program_url': url, **data}\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
        "        futures = {executor.submit(process_program, p): p for p in programs_with_urls}\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            if future.result(): scraped_results.append(future.result())\n",
        "\n",
        "    print(\"üß† Generating Embeddings...\")\n",
        "    texts = [f\"{item['program_name']} {item.get('prerequisites','')}\"[:2000] for item in scraped_results]\n",
        "    all_vectors = []\n",
        "    for i in range(0, len(texts), 50):\n",
        "        print(f\"Embedding batch {i}...\", end=\"\\r\")\n",
        "        all_vectors.extend(get_batch_embeddings(texts[i : i + 50]))\n",
        "        time.sleep(1)\n",
        "\n",
        "    all_programs_detailed_data = []\n",
        "    for i, item in enumerate(scraped_results):\n",
        "        if i < len(all_vectors):\n",
        "            item['embedding'] = all_vectors[i]\n",
        "            all_programs_detailed_data.append(item)\n",
        "    save_data(all_programs_detailed_data)\n",
        "\n",
        "# --- 6. LOGIC & STATE MANAGEMENT ---\n",
        "\n",
        "def find_best_matches(query, data, top_k=5):\n",
        "    q_vec = get_single_embedding(query)\n",
        "    valid_data = [x for x in data if 'embedding' in x]\n",
        "    db_vecs = [x['embedding'] for x in valid_data]\n",
        "    scores = cosine_similarity([q_vec], db_vecs)[0]\n",
        "    top_indices = scores.argsort()[-top_k:][::-1]\n",
        "    return [valid_data[i] for i in top_indices]\n",
        "\n",
        "# STEP 1: Generate the Initial Big Report\n",
        "def initial_report(subjects, interests, average, grade, location):\n",
        "    subjects_str = \", \".join(subjects) if subjects else \"None\"\n",
        "    log_interaction(grade, location, interests, subjects_str)\n",
        "\n",
        "    matches = find_best_matches(interests, all_programs_detailed_data)\n",
        "\n",
        "    # Store this context for the Chatbot to use later\n",
        "    context_data = {\n",
        "        \"profile\": f\"Grade: {grade}, Avg: {average}, Loc: {location}, Subj: {subjects_str}, Int: {interests}\",\n",
        "        \"matches\": matches\n",
        "    }\n",
        "\n",
        "    context_str = \"\"\n",
        "    for p in matches:\n",
        "        context_str += f\"- {p['program_name']} (Avg: {p['admission_average']})\\n  Prereqs: {p['prerequisites']}\\n  Link: {p['program_url']}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Act as 'Saarthi', a wise university guidance counselor.\n",
        "    PROFILE: {context_data['profile']}\n",
        "    MATCHES: {context_str}\n",
        "\n",
        "    INSTRUCTIONS:\n",
        "    1. **Rank & Recommend:** Recommend the top 10 programs.\n",
        "    2. **Prerequsite Check:** Compare \"Subjects\" vs \"Prereqs\". Warn if missing.\n",
        "    3. **Fit Analysis:** Explain fit.\n",
        "    4. **Extracurriculars:** Suggest side projects.\n",
        "    5. **COMMUTE ANALYSIS:** - Calculate estimated travel time from '{user_data['location']}' to the university.\n",
        "       - If > 1 hour, recommend RESIDENCE.\n",
        "       - Estimate Cost (GO Train/Gas).\n",
        "    6. **Tone:** Warm and supportive. Use emojis.\n",
        "    \"\"\"\n",
        "    response = chat.send_message(prompt).text\n",
        "\n",
        "    # Return 3 things:\n",
        "    # 1. The Chat History (User message + AI response)\n",
        "    # 2. The Context Data (saved to State)\n",
        "    # 3. Visibility update for the Follow-up Box\n",
        "    return [(None, response)], context_data, gr.update(visible=True)\n",
        "\n",
        "# STEP 2: Handle Follow-up Questions\n",
        "def follow_up_chat(user_message, history, context_data):\n",
        "    if not context_data:\n",
        "        return history + [(user_message, \"Please generate a report first!\")]\n",
        "\n",
        "    # Re-build context string from saved state\n",
        "    context_str = \"\"\n",
        "    for p in context_data['matches']:\n",
        "        context_str += f\"- {p['program_name']} (Avg: {p['admission_average']})\\n  Prereqs: {p['prerequisites']}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    CONTEXT:\n",
        "    The user previously asked for university advice.\n",
        "    Profile: {context_data['profile']}\n",
        "    University Options discussed: {context_str}\n",
        "\n",
        "    NEW USER QUESTION: \"{user_message}\"\n",
        "\n",
        "    INSTRUCTIONS:\n",
        "    Answer the question based on the University Options above.\n",
        "    If they ask about tuition, campus life, or specific details not in the text, use your general knowledge as an AI.\n",
        "    Keep it conversational.\n",
        "    \"\"\"\n",
        "\n",
        "    response = chat.send_message(prompt).text\n",
        "    history.append((user_message, response))\n",
        "    return history, \"\" # Return history and clear the textbox\n",
        "\n",
        "# --- 7. HYBRID UI (The Blocks System) ---\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
        "    # State holds data between clicks (Invisible to user)\n",
        "    session_state = gr.State()\n",
        "\n",
        "    gr.Markdown(\"# üèπ Saarthi: AI University Guide\")\n",
        "    gr.Markdown(\"Start by filling out your profile to get a custom roadmap. Then, chat with Saarthi to ask more questions!\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            # Input Section\n",
        "            inp_subjects = gr.Dropdown(ALL_COURSES, multiselect=True, label=\"Current Subjects\", allow_custom_value=True)\n",
        "            inp_interests = gr.Textbox(label=\"Interests (e.g. Robotics)\")\n",
        "            inp_avg = gr.Textbox(label=\"Average %\")\n",
        "            inp_grade = gr.Dropdown(GRADE_OPTIONS, label=\"Grade\")\n",
        "            inp_loc = gr.Textbox(label=\"Location (City, ON)\")\n",
        "\n",
        "            btn_generate = gr.Button(\"üöÄ Generate Roadmap\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            # Output Section\n",
        "            chatbot = gr.Chatbot(label=\"Saarthi's Advice\", height=550, bubble_full_width=False)\n",
        "\n",
        "            # Follow-up Box (Hidden until report is generated)\n",
        "            txt_followup = gr.Textbox(label=\"Ask a follow-up question...\", placeholder=\"e.g. 'How much is tuition?'\", visible=False)\n",
        "            btn_ask = gr.Button(\"Ask\", visible=False)\n",
        "\n",
        "    # EVENT 1: Generate Initial Report\n",
        "    btn_generate.click(\n",
        "        fn=initial_report,\n",
        "        inputs=[inp_subjects, inp_interests, inp_avg, inp_grade, inp_loc],\n",
        "        outputs=[chatbot, session_state, txt_followup] # Updates chat, saves state, shows text box\n",
        "    ).then(\n",
        "        # Also show the 'Ask' button\n",
        "        lambda: gr.update(visible=True), None, btn_ask\n",
        "    )\n",
        "\n",
        "    # EVENT 2: Ask Follow-up (Press Enter)\n",
        "    txt_followup.submit(\n",
        "        fn=follow_up_chat,\n",
        "        inputs=[txt_followup, chatbot, session_state],\n",
        "        outputs=[chatbot, txt_followup]\n",
        "    )\n",
        "\n",
        "    # EVENT 3: Ask Follow-up (Click Button)\n",
        "    btn_ask.click(\n",
        "        fn=follow_up_chat,\n",
        "        inputs=[txt_followup, chatbot, session_state],\n",
        "        outputs=[chatbot, txt_followup]\n",
        "    )\n",
        "\n",
        "app.launch(inline=True, share=True, debug=True)"
      ],
      "metadata": {
        "id": "BHAlICULBnw5",
        "outputId": "8d919534-2902-49c7-d6ef-a0f27fce722e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Connecting to Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚ö° Loaded 1399 programs from Drive.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3470407955.py:225: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
            "/tmp/ipython-input-3470407955.py:245: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Saarthi's Advice\", height=550, bubble_full_width=False)\n",
            "/tmp/ipython-input-3470407955.py:245: DeprecationWarning: The 'bubble_full_width' parameter will be removed in Gradio 6.0. This parameter no longer has any effect.\n",
            "  chatbot = gr.Chatbot(label=\"Saarthi's Advice\", height=550, bubble_full_width=False)\n",
            "/tmp/ipython-input-3470407955.py:245: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(label=\"Saarthi's Advice\", height=550, bubble_full_width=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://213b328ab877ce0f9d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://213b328ab877ce0f9d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://213b328ab877ce0f9d.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}